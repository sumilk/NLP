{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f8e646",
   "metadata": {},
   "source": [
    "# Text Representation in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021476bf",
   "metadata": {},
   "source": [
    "# Natural Language Processing: Text Classification with Vectorization\n",
    "\n",
    "## Objective\n",
    "The aim of this notebook is to demonstrate the process of transforming textual data into numerical form using two different vectorization techniques—CountVectorizer and TfidfVectorizer—and to employ a Logistic Regression model for the classification of text. We will focus on classifying text data as 'toxic' or 'non-toxic'.\n",
    "\n",
    "## Dataset\n",
    "We utilize a dataset from the Jigsaw Toxic Comment Classification Challenge, which comprises various user comments labeled for toxicity. The task is to predict the likelihood of a comment being toxic.\n",
    "\n",
    "## Methodology\n",
    "We begin by preprocessing the text data with custom tokenization using SpaCy, an advanced natural language processing library. This prepares our text data by converting it into tokens, lemmatizing, and filtering out stop words and punctuation.\n",
    "\n",
    "Next, we explore two vectorization methods:\n",
    "1. **CountVectorizer**: This method converts text documents to a matrix of token counts, effectively creating a bag-of-words model where the frequency of words is used as features.\n",
    "2. **TfidfVectorizer**: This technique produces a matrix of TF-IDF (Term Frequency-Inverse Document Frequency) features, giving importance to words based on their frequency in a document and across all documents.\n",
    "\n",
    "With our text data vectorized, we then train a Logistic Regression model to classify comments into toxic or non-toxic categories. This model is chosen for its efficiency and effectiveness in binary classification tasks.\n",
    "\n",
    "## Evaluation\n",
    "We evaluate the performance of our model using metrics such as accuracy, precision, recall, and F1 score, aiming to understand the strengths and limitations of each vectorization method in the context of text classification.\n",
    "\n",
    "By the end of this notebook, we will have a clear understanding of how to transform text data for machine learning purposes and how to implement a classification model on NLP tasks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn -q\n",
    "# !pip install spacy -q\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f6a976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b59db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440aac5",
   "metadata": {},
   "source": [
    "Loading the dataset from a CSV file related to the Jigsaw Toxic Comment Classification Challenge from Kaggle.\n",
    "\n",
    "Source: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8aeca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/jigsaw-toxic-comment-classification-challenge/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4433d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba35bd06",
   "metadata": {},
   "source": [
    "The DataFrame `data` contains the following columns:\n",
    "\n",
    "- `id`: A unique identifier for each comment.\n",
    "- `comment_text`: The text of the comment itself.\n",
    "- `toxic`: A binary indicator (0 or 1) for whether the comment is toxic.\n",
    "- `severe_toxic`: A binary indicator for whether the comment is severely toxic.\n",
    "- `obscene`: A binary indicator for whether the comment contains obscene language.\n",
    "- `threat`: A binary indicator for whether the comment contains a threat.\n",
    "- `insult`: A binary indicator for whether the comment is insulting.\n",
    "- `identity_hate`: A binary indicator for whether the comment contains hate speech against someone's identity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c40ca",
   "metadata": {},
   "source": [
    "## Using Spacy\n",
    "\n",
    "Loading Spacy Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b528c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45df635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'if', 'behind', 'about', 'rather', '’s', 'after', 'whether', 'anything', '’m', 'as', 'five', 'anyway', 'per', 'my', 'most', 'still', 'whose', 'should', 'have', 'unless', 'they', 'has', '‘s', 'once', \"'m\", 'no', 'up', 'elsewhere', 'of', 'at', 'any', 'so', 'throughout', 'together', 'everywhere', 'ca', 'these', 'hundred', 'four', 'yours', 'whom', 'both', 'in', 'front', 'others', 'somehow', 'eleven', 'could', 'would', 'became', 'very', 'do', '‘m', 'last', 'nobody', 'used', 'formerly', 'meanwhile', 'why', 'whenever', 'amongst', 'down', 'often', 'besides', 'two', 'go', 'ten', 'from', 'whereas', 'moreover', \"n't\", 'whole', 'many', 'them', 'sometime', 'anywhere', 'else', 'such', 'make', 'becoming', 'thru', 'among', 'into', 'indeed', 'itself', 'the', 'latterly', 'otherwise', 'that', 'themselves', 'also', 'its', 'various', 'did', 'hereafter', 'some', 'whither', 'me', 'really', 'on', 'however', 'anyhow', 'all', 're', 'move', 'never', 'fifty', 'he', 'above', 'thereafter', 'out', 'which', 'was', 'keep', 'here', 'get', 'one', 'hers', 'when', 'although', 'her', 'doing', 'may', 'forty', 'without', 'nor', 'give', 'our', 'we', 'sometimes', 'via', 'namely', \"'s\", 'always', 'are', 'least', 'were', 'onto', 'been', 'it', 'neither', 'same', 'first', 'name', 'seems', 'what', 'several', 'latter', 'ever', 'full', 'upon', 'now', 'within', 'while', 'beyond', 'fifteen', 'less', \"'re\", 'whoever', 'or', 'but', 'yourself', 'below', \"'d\", 'wherever', 'anyone', 'not', 'beside', 'empty', 'cannot', 'take', 'twenty', 'become', 'afterwards', 'each', 'quite', 'himself', 'toward', 'hereby', 'next', '‘d', 'across', 'am', 'every', 'much', 'amount', 'more', 'serious', 'eight', 'your', \"'ve\", 'another', 'everyone', 'third', 'for', '‘ve', 'thereupon', 'again', 'n‘t', 'where', 'nevertheless', 'an', 'seeming', 'yourselves', 'who', 'she', 'call', 'using', 'whereupon', '’ll', 'sixty', 'therefore', 'whatever', 'just', 'mine', 'thereby', 'yet', 'n’t', 'due', 'myself', 'under', 'something', 'had', 'since', 'his', 'ours', 'might', 'therein', 'back', 'off', 'will', 'though', 'enough', 'whereby', 'you', 'becomes', '‘ll', 'can', 'somewhere', 'this', 'whereafter', 'further', 'own', '’re', 'six', 'regarding', 'i', 'only', 'nothing', 'twelve', 'before', 'see', 'nine', 'top', 'either', 'until', 'nowhere', 'to', 'put', 'other', 'between', 'well', 'seem', 'wherein', 'hence', 'us', 'herself', 'except', 'and', 'someone', '’d', 'hereupon', 'almost', 'none', 'those', 'ourselves', '‘re', 'be', 'part', 'too', 'does', 'him', 'thence', 'former', \"'ll\", 'seemed', 'there', 'thus', 'how', 'then', 'along', 'is', 'made', 'over', 'side', 'beforehand', 'mostly', 'must', 'please', 'around', 'perhaps', 'because', 'than', 'three', 'even', 'say', 'against', 'during', 'bottom', '’ve', 'herein', 'everything', 'noone', 'a', 'alone', 'being', 'whence', 'already', 'their', 'with', 'by', 'done', 'few', 'show', 'towards', 'through'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = nlp.Defaults.stop_words\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a54c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "punctuations = string.punctuation\n",
    "print(punctuations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed37e2a",
   "metadata": {},
   "source": [
    "Custom tokenizer funtion for use with vectorization techniques like `CountVectorizer` and `TfidfVectorizer`. \n",
    "\n",
    "\n",
    "This custom tokenizer is more robust than default tokenizers and is beneficial for a couple of reasons:\n",
    "\n",
    "- **Lemmatization**: By using lemmas instead of the surface form of words, the model can more easily recognize that words like \"run\" and \"running\" are variations of the same concept, which can improve model performance.\n",
    "\n",
    "- **Case Normalization**: Converting all text to lower case helps the model treat words like \"The\" and \"the\" as the same word.\n",
    "\n",
    "- **Stop Words/Punctuation Removal**: Filtering out these reduces the number of features in the vectorized output and focuses the model's attention on the more meaningful content.\n",
    "\n",
    "The tokenizer is a key part of the preprocessing pipeline for NLP tasks, and when used in conjunction with vectorizers, it prepares the text data for model training, ensuring that the input features are representative of the semantic content of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "663817ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence): # uncomment print statements to see intermediate token states\n",
    "#     print(sentence)\n",
    "    \n",
    "    # parsing the input sentence usine spacy\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "#     print(doc)\n",
    "#     print(type(doc))\n",
    "\n",
    "    #creating a list of tokens by lemmatizing each word in the document\n",
    "    mytokens = [word.lemma_.lower() for word in doc]\n",
    "    \n",
    "#     print(mytokens)\n",
    "    \n",
    "    # filtering out tokens that are either stop words or punctuations\n",
    "    mytokens = [token for token in mytokens if token not in stop_words and token not in punctuations]\n",
    "    \n",
    "#     print(mytokens)\n",
    "    \n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8a996",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "\n",
    "`CountVectorizer` is a text analysis method that converts a collection of text documents into a matrix of token counts. This is part of the bag-of-words model, where the frequency (count) of each word is used as a feature for training a classifier.\n",
    "\n",
    "**Key points:**\n",
    "- It disregards grammar and word order but does capture multiplicity (i.e., how many times a word appears).\n",
    "- Each term found by the analyzer during the fit is assigned a unique integer index corresponding to a column in the resulting matrix.\n",
    "- This model can be very useful in cases where the occurrence of words is more important than the order in which they occur.\n",
    "\n",
    "**CountVectorizer Initialization:**\n",
    "   \n",
    "We will initialize `CountVectorizer` with the custom tokenizer, `spacy_tokenizer`, which is a more advanced approach compared to the default tokenizer as it can handle complex patterns in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "880aace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39d75e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"I am eating apple, I like apple\",\"I am playing cricket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f256ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the list of sentences into a document-term matrix.\n",
    "vectors = cv.fit_transform(sentences).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d16959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea7c1770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'cricket', 'eat', 'like', 'play'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature names to understand what each column in the vectors represents\n",
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f1c23f",
   "metadata": {},
   "source": [
    "The sentences have been vectorized into numerical arrays, and the vocabulary has been identified as `['apple', 'cricket', 'eat', 'like', 'play']`.\n",
    "\n",
    "The vectorized representation corresponds to the sentences as follows:\n",
    "\n",
    "1. For \"I am eating apple, I like apple\":\n",
    "   - `[2, 0, 1, 1, 0]`\n",
    "   - 'apple' appears twice, 'eat' once (it seems 'eating' has been reduced to its lemma 'eat'), 'like' once, and 'cricket' and 'play' do not appear.\n",
    "\n",
    "2. For \"I am playing cricket\":\n",
    "   - `[0, 1, 0, 0, 1]`\n",
    "   - 'cricket' and 'play' appear once each (again 'playing' has been reduced to 'play'), and 'apple', 'eat', and 'like' do not appear.\n",
    "\n",
    "\n",
    "Interpreting the vectorization results:\n",
    "\n",
    "- The vocabulary does not include common English stop words like \"I\" and \"am\", nor does it include the verb \"am\" and punctuation \",\", which have been removed by our custom tokenizer\n",
    "- The verbs 'eating' and 'playing' have been lemmatized to 'eat' and 'play', using the custom tokenizer\n",
    "- The counts in the vectors correspond to how many times each word in the vocabulary appears in each sentence.\n",
    "\n",
    "This vectorization process has effectively converted the text into a format suitable for use with machine learning algorithms, which require numerical input. The Logistic Regression model can now use these vectors to learn patterns associated with different categories (in this case, potentially toxic versus non-toxic comments if applied to the Jigsaw dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ca4062c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eat': 2, 'apple': 0, 'like': 3, 'play': 4, 'cricket': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5514e29e",
   "metadata": {},
   "source": [
    "### Applying the CountVectorizer on actual data for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3495a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['comment_text']\n",
    "y = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6798811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c54782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to use 5% of the data for model building\n",
    "# Set the test_size to 0.95 so that 5% remains as the training set\n",
    "# 5% of the data is randomly selected for model building while preserving the distribution of the 'toxic' column\n",
    "\n",
    "X, X_unused, y, y_unused = train_test_split(\n",
    "    X, y, test_size=0.95, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d0eb3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e507e82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6382,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "294d1f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9fe3f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e398fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vetcors = cv.fit_transform(X_train)\n",
    "X_test_vectors = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b771ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6382, 24542)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vetcors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aeb316b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vetcors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2a520ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vetcors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1dc859ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7321e997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9392230576441103"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "69fef744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "953f5b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47058823529411764"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0650217f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1443\n",
      "           1       0.82      0.47      0.60       153\n",
      "\n",
      "    accuracy                           0.94      1596\n",
      "   macro avg       0.88      0.73      0.78      1596\n",
      "weighted avg       0.93      0.94      0.93      1596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec2b1c5",
   "metadata": {},
   "source": [
    "### CountVectorizer Results\n",
    "\n",
    "- **Precision for Class 0 (Non-Toxic)**: 0.95 indicates that 95% of the comments predicted as non-toxic were indeed non-toxic.\n",
    "- **Recall for Class 0**: 0.99 shows that 99% of the actual non-toxic comments were correctly identified by the model.\n",
    "- **F1-Score for Class 0**: 0.97 is a high score, showing a good balance between precision and recall for non-toxic comments.\n",
    "\n",
    "- **Precision for Class 1 (Toxic)**: 0.82 means that 82% of the comments predicted as toxic were actually toxic.\n",
    "- **Recall for Class 1**: 0.47 indicates that the model could correctly identify only 47% of the actual toxic comments.\n",
    "- **F1-Score for Class 1**: 0.60, which is considerably lower than for Class 0, suggests that the model is less effective in correctly identifying toxic comments.\n",
    "\n",
    "- **Overall Accuracy**: 0.94 shows that the model correctly predicted 94% of the comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65fd72d",
   "metadata": {},
   "source": [
    "## TfidfVectorizer\n",
    "\n",
    "`TfidfVectorizer` converts a collection of raw documents to a matrix of TF-IDF features. TF-IDF stands for Term Frequency-Inverse Document Frequency, which reflects how important a word is to a document in a collection or corpus.\n",
    "\n",
    "**Key points:**\n",
    "- The TF (Term Frequency) of a word is the frequency of a word (i.e., number of times it appears) in a document.\n",
    "- The IDF (Inverse Document Frequency) is a measure of how significant a term is in the entire corpus. The IDF increases when the word is rare across documents and decreases when the word is common.\n",
    "- The TF-IDF value increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general.\n",
    "\n",
    "**TfidfVectorizer Initialization:**\n",
    "\n",
    "Similar to `CountVectorizer`, `TfidfVectorizer` is also initialized with the `spacy_tokenizer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "21c051ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c7308842",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = tfidf_vector.fit_transform(sentences).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1be4867d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81649658, 0.        , 0.40824829, 0.40824829, 0.        ],\n",
       "       [0.        , 0.70710678, 0.        , 0.        , 0.70710678]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16c3e1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'cricket', 'eat', 'like', 'play'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5ba65",
   "metadata": {},
   "source": [
    "The output shows the TF-IDF vectorized representation of the same sentences, with the vocabulary identified as `['apple', 'cricket', 'eat', 'like', 'play']`.\n",
    "\n",
    "The TF-IDF vectors are:\n",
    "\n",
    "1. For \"I am eating apple, I like apple\":\n",
    "   - `[0.81649658, 0., 0.40824829, 0.40824829, 0.]`\n",
    "   - 'apple' has the highest value since it is the most frequent term in this sentence but not the only term, so its TF-IDF score is high but not as high as if it were the only word in the document.\n",
    "   - 'eat' and 'like' have the same TF-IDF value, which is lower than 'apple' because they appear fewer times.\n",
    "   - 'cricket' and 'play' are not present in this sentence, hence their TF-IDF value is 0.\n",
    "\n",
    "2. For \"I am playing cricket\":\n",
    "   - `[0., 0.70710678, 0., 0., 0.70710678]`\n",
    "   - 'cricket' and 'play' have equal TF-IDF values, as they both appear once and are the only terms in the sentence.\n",
    "   - 'apple', 'eat', and 'like' do not appear in this sentence, so their TF-IDF values are 0.\n",
    "\n",
    "The values in the TF-IDF vectors are not simple counts, but rather weighted frequencies that are designed to reflect the importance of each term within the sentence as well as across the set of sentences. The TF-IDF score increases with the number of times a word appears in a document but is offset by the number of documents in the corpus that the word appears in. This is why TF-IDF is a popular feature extraction method for text data, as it can highlight words that are distinct to a particular document.\n",
    "\n",
    "Interpretation of the TF-IDF results:\n",
    "\n",
    "- The TF (term frequency) part of TF-IDF for 'apple' in the first sentence is high, as it appears twice.\n",
    "- The IDF (inverse document frequency) part lowers the weight for 'apple' slightly since it appears in half of the documents (1 out of 2 sentences), but not as much as if it appeared in all documents.\n",
    "- The word 'cricket' and 'play' have a lower TF in the second sentence (since they appear only once) but a higher IDF (since they do not appear in the first sentence), leading to a moderate TF-IDF score.\n",
    "- The values are normalized, which is why they are less than 1, and they are not integers like in the `CountVectorizer` output.\n",
    "\n",
    "The resulting vectors from `TfidfVectorizer` can now be used as input for machine learning models such as Logistic Regression, just like the ones from `CountVectorizer`. The difference is that the TF-IDF vectors provide a more nuanced representation that gives more weight to terms that are distinctive to each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4430d3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eat': 2, 'apple': 0, 'like': 3, 'play': 4, 'cricket': 1}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba18ecb",
   "metadata": {},
   "source": [
    "### Applying the TfidfVectorizer on actual data for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8ba37eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors_tf = tfidf_vector.fit_transform(X_train)\n",
    "X_test_vectors_tf = tfidf_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3c28cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 10899)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectors_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fef30625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3b1139ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_vectors_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d27646d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tf = model.predict(X_test_vectors_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ded5b964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9348370927318296"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7d3bec58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803921568627451"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test, y_pred_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cd9d5e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32679738562091504"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test, y_pred_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dd2d4310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      1443\n",
      "           1       0.98      0.33      0.49       153\n",
      "\n",
      "    accuracy                           0.93      1596\n",
      "   macro avg       0.96      0.66      0.73      1596\n",
      "weighted avg       0.94      0.93      0.92      1596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ff9b4",
   "metadata": {},
   "source": [
    "### TfidfVectorizer Results\n",
    "\n",
    "- **Precision for Class 0**: 0.93 shows high accuracy in predicting non-toxic comments.\n",
    "- **Recall for Class 0**: 1.00 indicates that all actual non-toxic comments were correctly identified.\n",
    "- **F1-Score for Class 0**: 0.97, which is excellent.\n",
    "\n",
    "- **Precision for Class 1**: 0.98 is very high, suggesting that almost all comments predicted as toxic were indeed toxic.\n",
    "- **Recall for Class 1**: 0.33 shows that the model missed many toxic comments, identifying only 33% of them correctly.\n",
    "- **F1-Score for Class 1**: 0.49, lower than that achieved with `CountVectorizer`.\n",
    "\n",
    "- **Overall Accuracy**: 0.93, slightly lower than the model trained with `CountVectorizer`.\n",
    "\n",
    "### Comparison and Interpretation\n",
    "\n",
    "- **Performance on Non-Toxic Comments (Class 0)**: Both models perform excellently in identifying non-toxic comments, with high precision, recall, and F1-scores.\n",
    "  \n",
    "- **Performance on Toxic Comments (Class 1)**: The model trained with `CountVectorizer` has a better balance between precision and recall for toxic comments, as indicated by the higher F1-score. The `TfidfVectorizer` model has higher precision but significantly lower recall, meaning it's more conservative in labeling comments as toxic.\n",
    "\n",
    "- **Overall Accuracy**: Both models have similar overall accuracy, but the `CountVectorizer` model has a slightly higher accuracy.\n",
    "\n",
    "- **Bias Towards Majority Class**: Both models show a tendency to perform better on the majority class (non-toxic), which is common in imbalanced datasets. The low recall for toxic comments (Class 1) in both models suggests that they struggle with identifying the minority class effectively.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "For this particular dataWhile both models are good at predicting non-toxic comments, there's a notable difference in how they handle toxic comments. The model with `CountVectorizer` provides a more balanced performance for the toxic class, making it potentially more suitable for scenarios where identifying toxic comments is crucial. However, the high precision but low recall of the `TfidfVectorizer` model might be preferable in situations where false positives (non-toxic comments labeled as toxic) are more problematic than false negatives (toxic comments not identified). Depending on the specific needs and tolerance for false positives/negatives, one might be chosen over the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a59f703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[358,   2],\n",
       "       [ 25,  15]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0227f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
